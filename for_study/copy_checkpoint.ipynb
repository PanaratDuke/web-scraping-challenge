{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from splinter import Browser\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/JeabD/bin/chromedriver\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Splinter to read html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract From NASA Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read html from website\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to store text from website\n",
    "top_article_title =\"\"\n",
    "top_article_body = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store html in var\n",
    "html = browser.html\n",
    "\n",
    "# Read html tags into var using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "titles = soup.find('div', class_=\"list_text\")\n",
    "\n",
    "# Find all the classes name under div class \"list_text\"\n",
    "for cur_div in titles.find_all('div'):\n",
    "    \n",
    "    if \"content_title\" in cur_div.attrs[\"class\"]:      \n",
    "        cur_a = cur_div.find('a')\n",
    "        top_article_title = cur_a.text\n",
    "    elif \"article_teaser_body\" in cur_div.attrs[\"class\"]:     \n",
    "        top_article_body = cur_div.text\n",
    "        \n",
    "\n",
    "print(top_article_title)\n",
    "top_article_body\n",
    "\n",
    "# dir(cur_div)\n",
    "# print(cur_div.attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from JPL Featured Space Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(jpl_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to store text from website\n",
    "feat_img_url = \"\"\n",
    "feat_img_url_1 = \"\"\n",
    "feat_img_url_2 = \"\"\n",
    "feat_img_url_new = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find image parth first part\n",
    "find_div_1 = soup.find('div', class_=\"jpl_logo\")\n",
    "feat_img_url_1 = find_div_1.a['href']\n",
    "\n",
    "feat_img_url_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find image parth first part\n",
    "find_div_raw = soup.find('li', class_=\"slide\")\n",
    "feat_img_url = find_div_raw.a['data-fancybox-href']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_img_url_strip = feat_img_url.split('/')\n",
    "feat_img_url_strip\n",
    "# feat_img_url_2 = (f\"{feat_img_url_strip[1]}/{feat_img_url_strip[2]}\")\n",
    "feat_img_url_2 = (f\"{feat_img_url_strip[1]}/{feat_img_url_strip[2]}/{feat_img_url_strip[3]}/{feat_img_url_strip[4]}\")\n",
    "feat_img_url_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_img_url = (f\"https:{feat_img_url_1}{feat_img_url_2}\")\n",
    "feat_img_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Mars Weather from twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_url = 'https://twitter.com/marswxreport?lang=en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "browser.visit(twitter_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Mars Weather from attributes\n",
    "\n",
    "mars_weather = soup.find_all('div', attrs={'data-testid': 'tweet'})\n",
    "# len(mars_weather)\n",
    "for each_soup in mars_weather[0]: \n",
    "    try:\n",
    "        print_mars_weather = each_mars_weather.find('div', class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\").find('span',class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\").text\n",
    "        print(print_mars_weather)\n",
    "        break\n",
    "    except:\n",
    "        print('e')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Mar Facts from space-facts.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url)\n",
    "type(tables)\n",
    "# There are four tables in the webpage\n",
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tables[0]\n",
    "# tables[1]\n",
    "# tables[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mars Facts\n",
    "mars_facts = pd.DataFrame(tables[3])\n",
    "mars_facts\n",
    "# mars_facts_df = mars_facts.set_index(0)\n",
    "# print(type(mars_facts_df))\n",
    "# mars_facts.reset_index(0)\n",
    "# mars_facts.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to be in the same level\n",
    "# mars_facts_df.reset_index(level=[0, 1])\n",
    "# mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts.rename(columns={0:\"description\", \\\n",
    "                           1:\"value\"}, inplace=True)\n",
    "# mars_facts_df = mars_facts.set_index(\"description\")\n",
    "type(mars_facts)\n",
    "\n",
    "print(mars_facts.columns)\n",
    "\n",
    "mars_facts.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(mars_facts)\n",
    "mars_facts_tb = mars_facts.set_index('description')\n",
    "mars_facts_tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Mars Hemispheres from USGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "usgs_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "img_url = \"\"\n",
    "title = \"\"\n",
    "hemisphere_image_urls ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(usgs_url)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dict = {'key1':'geeks', 'key2':'for'}  \n",
    "print(\"Current Dict is: \", dict)  \n",
    "  \n",
    "# adding dict1 (key3, key4 and key5) to dict  \n",
    "dict1 = {'key3':'geeks', 'key4':'is', 'key5':'fabulous'}  \n",
    "dict.update(dict1)  \n",
    "  \n",
    "# by assigning  \n",
    "dict.update(newkey1 ='portal')  \n",
    "print(dict)  \n",
    "\n",
    "result.find('h1', class_='article-item__headline').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'append',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'count',\n",
       " 'extend',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'pop',\n",
       " 'remove',\n",
       " 'reverse',\n",
       " 'sort',\n",
       " 'source']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = browser.html\n",
    "\n",
    "# Read html tags into var using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "titles = soup.find_all('div', class_=\"item\")\n",
    "# len(titles)\n",
    "# type(titles)\n",
    "dir(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerberus Hemisphere Enhanced\n",
      "http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
      "Schiaparelli Hemisphere Enhanced\n",
      "http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
      "Syrtis Major Hemisphere Enhanced\n",
      "http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
      "Valles Marineris Hemisphere Enhanced\n",
      "http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for each_title in titles: \n",
    "    test = each_title.find('h3')\n",
    "    print(test.text)\n",
    "    browser.find_link_by_partial_text('Hemisphere Enhanced').click()\n",
    "    # you can access the attribute using [href]\n",
    "    img_url = browser.find_link_by_text('Sample').first['href']\n",
    "\n",
    "    print(img_url)\n",
    "    \n",
    "    browser.back()\n",
    "# print(titles.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "Cerberus Hemisphere Enhanced\n",
      "2:\n",
      "Schiaparelli Hemisphere Enhanced\n",
      "3:\n",
      "Syrtis Major Hemisphere Enhanced\n",
      "4:\n",
      "Valles Marineris Hemisphere Enhanced\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for each_title in titles: \n",
    "    print(f\"{count}:\")\n",
    "    test = each_title.find('h3')\n",
    "    print(test.text)\n",
    "    count +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/search/map/Mars/Viking/cerberus_enhanced\n",
      "/search/map/Mars/Viking/schiaparelli_enhanced\n",
      "/search/map/Mars/Viking/syrtis_major_enhanced\n",
      "/search/map/Mars/Viking/valles_marineris_enhanced\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for each_title in titles: \n",
    "    browser.find_link_by_partial_text('Hemisphere Enhanced').click()\n",
    "#     img_url = browser.find_link_by_text('Sample')\n",
    "    \n",
    "    img_url = each_title.a['href']\n",
    "\n",
    "    print(img_url)\n",
    "    \n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tag = browser.find_by_tag('h3') \n",
    "print(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'click_link_by_partial_href' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7075fc76c55c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhref_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclick_link_by_partial_href\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_href\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(href_found)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# dir(href_found)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'click_link_by_partial_href' is not defined"
     ]
    }
   ],
   "source": [
    "href_found = click_link_by_partial_href(partial_href)(\"https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced\")\n",
    "# print(href_found)\n",
    "# dir(href_found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href_found.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the classes name under div class \"collapsible results\"\n",
    "for cur_div in titles.find_all('div'):\n",
    "    \n",
    "    if \"content_title\" in cur_div.attrs[\"class\"]:      \n",
    "        cur_a = cur_div.find('a')\n",
    "        top_article_title = cur_a.text\n",
    "    elif \"article_teaser_body\" in cur_div.attrs[\"class\"]:     \n",
    "        top_article_body = cur_div.text\n",
    "        \n",
    "\n",
    "print(top_article_title)\n",
    "top_article_body"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

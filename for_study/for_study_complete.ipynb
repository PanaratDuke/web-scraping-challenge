{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "from splinter import Browser\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/JeabD/bin/chromedriver\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Splinter to read html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract From NASA Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = 'https://mars.nasa.gov/news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read html from website\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to store text from website\n",
    "top_article_title =\"\"\n",
    "top_article_body = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tat : How NASA's Perseverance Mars Team Adjusted to Work in the Time of Coronavirus \n",
      "tab: Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.\n",
      "\n",
      "\n",
      "dict= {\"How NASA's Perseverance Mars Team Adjusted to Work in the Time of Coronavirus \": 'Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.'}\n"
     ]
    }
   ],
   "source": [
    "# Store html in var\n",
    "html = browser.html\n",
    "\n",
    "# Read html tags into var using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "titles = soup.find('div', class_=\"list_text\")\n",
    "\n",
    "nasa_news = {}\n",
    "# Find all the classes name under div class \"list_text\"\n",
    "for cur_div in titles.find_all('div'):\n",
    "    \n",
    "    if \"content_title\" in cur_div.attrs[\"class\"]:      \n",
    "        cur_a = cur_div.find('a')\n",
    "        top_article_title = cur_a.text\n",
    "    if \"article_teaser_body\" in cur_div.attrs[\"class\"]:     \n",
    "        top_article_body = cur_div.text\n",
    "    nasa_news[top_article_title] = top_article_body\n",
    "    # traverse through the dictionary using [] and use = to set value as \n",
    "        \n",
    "\n",
    "print(f\"tat : {top_article_title}\\ntab: {top_article_body}\\n\\n\")\n",
    "# print(f\"tab : {top_article_body}\")\n",
    "\n",
    "# nasa_news = {top_article_title:top_article_body}\n",
    "# nasa_news.to_csv(\"nasa.csv\")\n",
    "print(f\"dict= {nasa_news}\")\n",
    "\n",
    "# dir(cur_div)\n",
    "# print(cur_div.attrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract from JPL Featured Space Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(jpl_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to store text from website\n",
    "feat_img_url = \"\" \n",
    "feat_img_url_1 = \"\"\n",
    "feat_img_url_2 = \"\" #Using This one to retrieve url\n",
    "feat_img_url_new = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.jpl.nasa.gov/'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find image parth first part\n",
    "find_div_1 = soup.find('div', class_=\"jpl_logo\")\n",
    "feat_img_url_1 = find_div_1.a['href']\n",
    "\n",
    "feat_img_url_1='http:'+feat_img_url_1\n",
    "feat_img_url_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/spaceimages/images/largesize/PIA23844_hires.jpg'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find image parth first part\n",
    "find_div_raw = soup.find('li', class_=\"slide\")\n",
    "feat_img_url = find_div_raw.a['data-fancybox-href']\n",
    "feat_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.jpl.nasa.gov/spaceimages/images/largesize/PIA23844_hires.jpg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feat_img_url_strip = feat_img_url.split('/')\n",
    "feat_img_url_2=feat_img_url_1+feat_img_url[1:]\n",
    "feat_img_url_2\n",
    "# feat_img_url_strip=feat_img_url[1, feat_img_url.length())\n",
    "# feat_img_url_strip\n",
    "# feat_img_url_2 = (f\"{feat_img_url_strip[1]}/{feat_img_url_strip[2]}\")\n",
    "# feat_img_url_2 = (f\"{feat_img_url_strip[1]}/{feat_img_url_strip[2]}/{feat_img_url_strip[3]}/{feat_img_url_strip[4]}\")\n",
    "# feat_img_url_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Mars Weather from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_url = 'https://twitter.com/marswxreport?lang=en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "browser.visit(twitter_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Mars Weather from attributes\n",
    "extract_mars_weather = soup.find_all('div', attrs={'data-testid': 'tweet'})\n",
    "for each_weather in extract_mars_weather: \n",
    "    mars_weather = each_weather.find_all('span')[4].text\n",
    "    print(mars_weather)\n",
    "# .find('div', class_=\"css-901oao r-hkyrab\").text\n",
    "# mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is alternative method using try:\n",
    "# mars_weather = soup.find_all('div', attrs={'data-testid': 'tweet'})\n",
    "# len(mars_weather)\n",
    "# for each_mars_weather in mars_weather[0]: \n",
    "#     try:\n",
    "#         print_mars_weather = each_mars_weather.find('div', class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\").find('span',class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\").text\n",
    "#         print(print_mars_weather)\n",
    "#         break\n",
    "#     except:\n",
    "#         print('e')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Mar Facts from Space Facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to contain mars facts data frame\n",
    "mars_facts = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url)\n",
    "type(tables)\n",
    "# There are four tables in the webpage\n",
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0]\n",
    "# tables[0].columns\n",
    "# tables[0].loc[:1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_demo={}\n",
    "# print(dict_demo)\n",
    "# dict_demo['key']='value'\n",
    "# print(dict_demo)\n",
    "# dict_demo['key2']='value2'\n",
    "# print(dict_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tables[0]\n",
    "# print(tables[1])\n",
    "# tables[2]\n",
    "info_dict={}\n",
    "target_table=tables[0]\n",
    "for each_row in target_table.index:\n",
    "    each_row_df=target_table.loc[each_row]\n",
    "    # dictionary={key: value, key2:value2}\n",
    "    # dictionary_name[key]=value\n",
    "    info_dict[each_row_df[0]]=each_row_df[1]\n",
    "#     print(info_dict[target_table.loc[each_row][0]]=target_table.loc[each_row][1])\n",
    "print(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mars Facts\n",
    "mars_facts = pd.DataFrame(tables[0])\n",
    "mars_facts\n",
    "# mars_facts_df = mars_facts.set_index(0)\n",
    "# print(type(mars_facts_df))\n",
    "# mars_facts.reset_index(0)\n",
    "# mars_facts.describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to be in the same level\n",
    "# mars_facts_df.reset_index(level=[0, 1])\n",
    "# mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts.rename(columns={0:\"description\", \\\n",
    "                           1:\"value\"}, inplace=True)\n",
    "# mars_facts_df = mars_facts.set_index(\"description\")\n",
    "type(mars_facts)\n",
    "\n",
    "print(mars_facts.columns)\n",
    "\n",
    "mars_facts.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(mars_facts)\n",
    "mars_facts_tb = mars_facts.set_index('description')\n",
    "mars_facts_tb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Mars Hemispheres from USGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usgs_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to contain images and title of the images \n",
    "img_url = \"\"\n",
    "title = \"\"\n",
    "hemisphere_image_urls ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(usgs_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "\n",
    "# Read html tags into var using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "titles = soup.find_all('div', class_=\"item\")\n",
    "# len(titles)\n",
    "# type(titles)\n",
    "# dir(titles)\n",
    "# titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_title in titles: \n",
    "    test = each_title.find('h3').text\n",
    "    print(test)\n",
    "#     browser.find_link_by_partial_text('Hemisphere Enhanced').click()\n",
    "    browser.find_link_by_partial_text(test).click()\n",
    "#     print(browser.url)\n",
    "    # you can access the attribute using [href]\n",
    "    img_url = browser.find_link_by_text('Sample').first['href']\n",
    "#     hemisphere_image_urls.update({test.text:img_url})\n",
    "    print(img_url)\n",
    "    \n",
    "    browser.back()\n",
    "# print(titles.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_title in titles: \n",
    "    print(f\"{count}:\")\n",
    "    test = each_title.find('h3')\n",
    "    print(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls={}\n",
    "for each_title in titles: \n",
    "    \n",
    "    browser.find_link_by_partial_text('Hemisphere Enhanced').click()\n",
    "    img_url = each_title.a['href']\n",
    "    print(img_url)\n",
    "    title = each_title.find('h3')\n",
    "#     print(type(title))\n",
    "#     hemisphere_image_urls.update({title.text:img_url})\n",
    "    \n",
    "#     hemisphere_image_urls.update(title)\n",
    "    print(f\"Key = {title}: Value = {img_url}\")\n",
    "    \n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls.items()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tag = browser.find_by_tag('h3') \n",
    "print(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
